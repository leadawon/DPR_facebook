{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, RagRetriever, RagModel\n",
    "# import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
    "# retriever = RagRetriever.from_pretrained(\n",
    "#     \"facebook/rag-token-base\", index_name=\"exact\", use_dummy_dataset=True\n",
    "# )\n",
    "# # initialize with RagRetriever to do everything in one forward call\n",
    "# model = RagModel.from_pretrained(\"facebook/rag-token-base\", retriever=retriever)\n",
    "\n",
    "# inputs = tokenizer(\"what is capital city of French?\", return_tensors=\"pt\")\n",
    "# outputs = model(input_ids=inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "# import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/rag-sequence-nq\")\n",
    "# retriever = RagRetriever.from_pretrained(\n",
    "#     \"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True\n",
    "# )\n",
    "# # initialize with RagRetriever to do everything in one forward call\n",
    "# model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "\n",
    "# inputs = tokenizer(\"How many people live in Paris?\", return_tensors=\"pt\")\n",
    "# targets = tokenizer(text_target=\"In Paris, there are 10 million people.\", return_tensors=\"pt\")\n",
    "# input_ids = inputs[\"input_ids\"]\n",
    "# labels = targets[\"input_ids\"]\n",
    "# outputs = model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "# # or use retriever separately\n",
    "# model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", use_dummy_dataset=True)\n",
    "# # 1. Encode\n",
    "# question_hidden_states = model.question_encoder(input_ids)[0]\n",
    "# # 2. Retrieve\n",
    "# docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\n",
    "# doc_scores = torch.bmm(\n",
    "#     question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n",
    "# ).squeeze(1)\n",
    "# # 3. Forward to generator\n",
    "\n",
    "\n",
    "# generated = model.generate(\n",
    "#     context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "#     context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "#     doc_scores=doc_scores,\n",
    "# )\n",
    "# generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, RagRetriever, RagTokenForGeneration\n",
    "# import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "# retriever = RagRetriever.from_pretrained(\n",
    "#     \"facebook/rag-token-nq\", index_name=\"exact\", use_dummy_dataset=True\n",
    "# )\n",
    "# # initialize with RagRetriever to do everything in one forward call\n",
    "# model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "\n",
    "# inputs = tokenizer(\"How many people live in Paris?\", return_tensors=\"pt\")\n",
    "# targets = tokenizer(text_target=\"In Paris, there are 10 million people.\", return_tensors=\"pt\")\n",
    "# input_ids = inputs[\"input_ids\"]\n",
    "# labels = targets[\"input_ids\"]\n",
    "# outputs = model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "# # or use retriever separately\n",
    "# model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", use_dummy_dataset=True)\n",
    "# # 1. Encode\n",
    "# question_hidden_states = model.question_encoder(input_ids)[0]\n",
    "# # 2. Retrieve\n",
    "# docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\n",
    "# doc_scores = torch.bmm(\n",
    "#     question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n",
    "# ).squeeze(1)\n",
    "# # 3. Forward to generator\n",
    "# outputs = model(\n",
    "#     context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "#     context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "#     doc_scores=doc_scores,\n",
    "#     decoder_input_ids=labels,\n",
    "# )\n",
    "\n",
    "# # or directly generate\n",
    "# generated = model.generate(\n",
    "#     context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "#     context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "#     doc_scores=doc_scores,\n",
    "# )\n",
    "# generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "\n",
    "# print(generated_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, RagRetriever, RagTokenForGeneration\n",
    "# import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "# retriever = RagRetriever.from_pretrained(\n",
    "#     \"facebook/rag-token-nq\", index_name=\"exact\", use_dummy_dataset=True\n",
    "# )\n",
    "# # initialize with RagRetriever to do everything in one forward call\n",
    "# model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "\n",
    "# inputs = tokenizer(\"Who is Trump?\", return_tensors=\"pt\")\n",
    "# targets = tokenizer(text_target=\"In China, there are 10 million people.\", return_tensors=\"pt\")\n",
    "# input_ids = inputs[\"input_ids\"]\n",
    "# labels = targets[\"input_ids\"]\n",
    "# outputs = model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "# # or use retriever separately\n",
    "# model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", use_dummy_dataset=True)\n",
    "# # 1. Encode\n",
    "# question_hidden_states = model.question_encoder(input_ids)[0]\n",
    "# # 2. Retrieve\n",
    "# docs_dict = retriever(input_ids.numpy(), question_hidden_states.detach().numpy(), return_tensors=\"pt\")\n",
    "# doc_scores = torch.bmm(\n",
    "#     question_hidden_states.unsqueeze(1), docs_dict[\"retrieved_doc_embeds\"].float().transpose(1, 2)\n",
    "# ).squeeze(1)\n",
    "# # 3. Forward to generator\n",
    "# outputs = model(\n",
    "#     context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "#     context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "#     doc_scores=doc_scores,\n",
    "#     decoder_input_ids=labels,\n",
    "# )\n",
    "\n",
    "# # or directly generate\n",
    "# generated = model.generate(\n",
    "#     context_input_ids=docs_dict[\"context_input_ids\"],\n",
    "#     context_attention_mask=docs_dict[\"context_attention_mask\"],\n",
    "#     doc_scores=doc_scores,\n",
    "# )\n",
    "# generated_string = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "\n",
    "# print(generated_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 위 코드 좀 이상함....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n",
    "\n",
    "# tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "# retriever = RagRetriever.from_pretrained(\"facebook/rag-token-nq\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "# model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "\n",
    "# input_dict = tokenizer.prepare_seq2seq_batch(\"who is the president of USA?\", return_tensors=\"pt\") \n",
    "\n",
    "# generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "# print(tokenizer.batch_decode(generated, skip_special_tokens=True)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration \n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "# with warnings.catch_warnings():\n",
    "#     warnings.simplefilter(\"ignore\")\n",
    "#     tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\") \n",
    "#     retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True) \n",
    "#     model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever=retriever) \n",
    "\n",
    "#     input_dict = tokenizer.prepare_seq2seq_batch(\"how many countries are in europe?\", return_tensors=\"pt\") \n",
    "\n",
    "#     generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "#     print(tokenizer.batch_decode(generated, skip_special_tokens=True)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pip install faiss-cpu --no-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import RagTokenizer, RagRetriever, RagTokenForGeneration\n",
    "\n",
    "# tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "# retriever = RagRetriever.from_pretrained(\"facebook/rag-token-nq\", index_name=\"exact\", use_dummy_dataset=True)\n",
    "# model = RagTokenForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "\n",
    "# input_dict = tokenizer.prepare_seq2seq_batch(\"where is capital city of France?\", return_tensors=\"pt\") \n",
    "\n",
    "# generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "# print(tokenizer.batch_decode(generated, skip_special_tokens=True)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for research block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/decs_jupyter_lab/venvs/bartvenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n",
      "Found cached dataset wiki_dpr (/root/.cache/huggingface/datasets/wiki_dpr/dummy.psgs_w100.nq.no_index-dummy=True,with_index=False/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54)\n",
      "Found cached dataset wiki_dpr (/root/.cache/huggingface/datasets/wiki_dpr/dummy.psgs_w100.nq.exact-df1b7a7f4307b5db/0.0.0/74d4bff38a7c18a9498fafef864a8ba7129e27cb8d71b22f5e14d84cb17edd54)\n",
      "Some weights of the model checkpoint at facebook/rag-sequence-nq were not used when initializing RagSequenceForGeneration: ['rag.question_encoder.question_encoder.bert_model.pooler.dense.weight', 'rag.question_encoder.question_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RagSequenceForGeneration from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RagSequenceForGeneration from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/leadawon5/decs_jupyter_lab/venvs/bartvenv/lib/python3.7/site-packages/transformers/models/rag/tokenization_rag.py:92: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  FutureWarning,\n",
      "/home/leadawon5/decs_jupyter_lab/venvs/bartvenv/lib/python3.7/site-packages/transformers/generation/utils.py:1358: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  UserWarning,\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Antarctic Treaty System / The Antarctic Treaty System's yearly \"Antarctic Treaty Consultative Meetings (ATCM)\" are the international forum for the administration and management of the region. Only 29 of the 53 parties to the agreements have the right to participate in decision-making at these meetings, though the other 24 are still allowed to attend. The decision-making participants are the \"Consultative Parties\" and, in addition to the 12 original signatories, include 17 countries that have demonstrated their interest in Antarctica by carrying out substantial scientific activity there. As of 2015, there are 53 states party to the treaty, 29 of which, including all 12 original // how many countries are in europe?\n",
      " Asia / Caucasus Mountains (or the Kuma–Manych Depression) and the Caspian and Black Seas. It is bounded on the east by the Pacific Ocean, on the south by the Indian Ocean and on the north by the Arctic Ocean. Asia is subdivided into 48 countries, three of them (Russia, Kazakhstan and Turkey) having part of their land in Europe. Asia has extremely diverse climates and geographic features. Climates range from arctic and subarctic in Siberia to tropical in southern India and Southeast Asia. It is moist across southeast sections, and dry across much of the interior. Some of the largest daily temperature // how many countries are in europe?\n",
      " Antarctic Treaty System / Antarctic Treaty System The Antarctic Treaty and related agreements, collectively known as the Antarctic Treaty System (ATS), regulate international relations with respect to Antarctica, Earth's only continent without a native human population. For the purposes of the treaty system, Antarctica is defined as all of the land and ice shelves south of 60°S latitude. The treaty entered into force in 1961 and currently has 53 parties. The treaty sets aside Antarctica as a scientific preserve, establishes freedom of scientific investigation, and bans military activity on the continent. The treaty was the first arms control agreement established during the Cold War. // how many countries are in europe?\n",
      " Antarctic Treaty System / South African residents and members of expeditions organised in South Africa. Antarctic Treaty System The Antarctic Treaty and related agreements, collectively known as the Antarctic Treaty System (ATS), regulate international relations with respect to Antarctica, Earth's only continent without a native human population. For the purposes of the treaty system, Antarctica is defined as all of the land and ice shelves south of 60°S latitude. The treaty entered into force in 1961 and currently has 53 parties. The treaty sets aside Antarctica as a scientific preserve, establishes freedom of scientific investigation, and bans military activity on the continent. The treaty // how many countries are in europe?\n",
      " Anatolia / Anatolia Anatolia (from Greek '; \"east\" or \"[sun]rise\"), also known as Asia Minor (Medieval and Modern Greek: ', \"small Asia\"; ), Asian Turkey, the Anatolian peninsula, or the Anatolian plateau, is the westernmost protrusion of Asia, which makes up the majority of modern-day Turkey. The region is bounded by the Black Sea to the north, the Mediterranean Sea to the south, the Armenian Highlands to the east, and the Aegean Sea to the west. The Sea of Marmara forms a connection between the Black and Aegean Seas through the Bosphorus and Dardanelles straits and separates Anatolia from Thrace on the // how many countries are in europe?\n",
      " 54\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argument 'ids': 'list' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2979836/815854861.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# index error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/leadawon5/decs_jupyter_lab/venvs/bartvenv/lib/python3.7/site-packages/transformers/models/rag/tokenization_rag.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leadawon5/decs_jupyter_lab/venvs/bartvenv/lib/python3.7/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3511\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3512\u001b[0m             \u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_up_tokenization_spaces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3513\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3514\u001b[0m         )\n\u001b[1;32m   3515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/leadawon5/decs_jupyter_lab/venvs/bartvenv/lib/python3.7/site-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         clean_up_tokenization_spaces = (\n",
      "\u001b[0;31mTypeError\u001b[0m: argument 'ids': 'list' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration \n",
    "# import inspect\n",
    "\n",
    "\n",
    "\n",
    "# tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\") \n",
    "# retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True) \n",
    "# model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever=retriever) \n",
    "\n",
    "# input_dict = tokenizer.prepare_seq2seq_batch(\"how many countries are in europe?\", return_tensors=\"pt\") \n",
    "\n",
    "# generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "# print(tokenizer.batch_decode(generated, skip_special_tokens=True)[0]) \n",
    "# print(tokenizer.batch_decode(generated, skip_special_tokens=True)[1])  # index error\n",
    "# print(tokenizer.batch_decode(generated, skip_special_tokens=True)[2]) \n",
    "# print(tokenizer.batch_decode(generated, skip_special_tokens=True)[3]) \n",
    "# print(tokenizer.batch_decode(generated, skip_special_tokens=True)[4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 54\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(generated[0], skip_special_tokens=True))  # index error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration \n",
    "import inspect\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\") \n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True) \n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever=retriever) \n",
    "\n",
    "input_dict = tokenizer.prepare_seq2seq_batch(\"how many countries are in asia?\", return_tensors=\"pt\") \n",
    "\n",
    "generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "print(tokenizer.batch_decode(generated, skip_special_tokens=True)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration \n",
    "import inspect\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-sequence-nq\") \n",
    "retriever = RagRetriever.from_pretrained(\"facebook/rag-sequence-nq\", index_name=\"exact\", use_dummy_dataset=True) \n",
    "model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-sequence-nq\", retriever=retriever) \n",
    "\n",
    "input_dict = tokenizer.prepare_seq2seq_batch(\"\", return_tensors=\"pt\") \n",
    "\n",
    "generated = model.generate(input_ids=input_dict[\"input_ids\"]) \n",
    "print(tokenizer.batch_decode(generated, skip_special_tokens=True)[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bartvenv",
   "language": "python",
   "name": "bartvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
