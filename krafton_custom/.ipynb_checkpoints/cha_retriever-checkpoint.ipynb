{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\"\n",
    "import torch\n",
    "import json\n",
    "from ast import literal_eval # 걍 eval쓰면 스트링을 배열로 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, DPRQuestionEncoder, DPRContextEncoder\n",
    "from typing import List\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "class BiEncoderRetriever:\n",
    "    def __init__(self) -> None:\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-question-encoder\")\n",
    "        self.question_encoder = DPRQuestionEncoder.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-question-encoder\").to(self.device)\n",
    "        self.ctxt_encoder = DPRContextEncoder.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-ctx-encoder\").to(self.device)\n",
    "\n",
    "    def encode_summaries(self, summaries: List[str]):\n",
    "        input_dict = self.tokenizer(summaries, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        del input_dict[\"token_type_ids\"]\n",
    "        return self.ctxt_encoder(**input_dict)['pooler_output']\n",
    "\n",
    "    def encode_question(self, question: str):\n",
    "        input_dict = self.tokenizer(question, padding='max_length', max_length=32, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        del input_dict[\"token_type_ids\"]\n",
    "        return self.question_encoder(**input_dict)['pooler_output']\n",
    "\n",
    "    def retrieve_top_summaries(self, question: str, summaries: List[str], encoded_summaries: np.ndarray = None, topk: int = 5):\n",
    "        encoded_question = self.encode_question(question)\n",
    "        if encoded_summaries is None:\n",
    "            encoded_summaries = self.encode_summaries(summaries)\n",
    "        else:\n",
    "            encoded_summaries = torch.from_numpy(encoded_summaries).to(self.device)\n",
    "\n",
    "        scores = torch.mm(encoded_question, encoded_summaries.T)\n",
    "        # print(encoded_question.shape)\n",
    "        # print(encoded_summaries.T.shape)\n",
    "        if topk >= len(summaries):\n",
    "            return summaries\n",
    "        top_k = torch.topk(scores, topk).indices.squeeze()\n",
    "        \n",
    "        #print(\"all scores : \")\n",
    "        #for i,v in enumerate(scores[0]):\n",
    "            #print(int(v.item()),end=\" \")\n",
    "        #print()\n",
    "        \n",
    "        return [summaries[i] for i in top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = BiEncoderRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start!\n",
      "now 0 dialog\n",
      "now 1 dialog\n",
      "now 2 dialog\n",
      "now 3 dialog\n",
      "now 4 dialog\n",
      "now 5 dialog\n",
      "now 6 dialog\n",
      "now 7 dialog\n",
      "now 8 dialog\n",
      "now 9 dialog\n",
      "now 10 dialog\n",
      "now 11 dialog\n",
      "now 12 dialog\n",
      "now 13 dialog\n",
      "now 14 dialog\n",
      "now 15 dialog\n",
      "now 16 dialog\n",
      "now 17 dialog\n",
      "now 18 dialog\n",
      "now 19 dialog\n",
      "now 20 dialog\n",
      "now 21 dialog\n",
      "now 22 dialog\n",
      "now 23 dialog\n",
      "now 24 dialog\n",
      "now 25 dialog\n",
      "now 26 dialog\n",
      "now 27 dialog\n",
      "now 28 dialog\n",
      "now 29 dialog\n",
      "now 30 dialog\n",
      "now 31 dialog\n",
      "now 32 dialog\n",
      "now 33 dialog\n",
      "now 34 dialog\n",
      "now 35 dialog\n",
      "now 36 dialog\n",
      "now 37 dialog\n",
      "now 38 dialog\n",
      "now 39 dialog\n",
      "now 40 dialog\n",
      "now 41 dialog\n",
      "now 42 dialog\n",
      "now 43 dialog\n",
      "now 44 dialog\n",
      "now 45 dialog\n",
      "now 46 dialog\n",
      "now 47 dialog\n"
     ]
    }
   ],
   "source": [
    "with open(\"./output.jsonl\",\"w\") as fout:\n",
    "    print(\"start!\")\n",
    "\n",
    "with open(\"./persona_dialog.jsonl\", \"r\") as dialogs:\n",
    "    for num,dialog in enumerate(dialogs):\n",
    "        if num == 500:\n",
    "            break;\n",
    "        else:\n",
    "            print(f\"now {num} dialog\")\n",
    "        dic = literal_eval(dialog)\n",
    "        dialog_list = dic[\"current\"]\n",
    "        persona_list = dic[\"persona_list\"]\n",
    "        \n",
    "        \n",
    "        with open(\"./output.jsonl\",\"a\") as fout:\n",
    "            resultlist = []\n",
    "            for i,v in enumerate(dialog_list):\n",
    "                \n",
    "                question = \"\".join(v.split()[2:])\n",
    "                personalist = persona_list\n",
    "                resultlist.append(rt.retrieve_top_summaries(question, personalist, None, topk=3))\n",
    "            epl_list = []\n",
    "            for d,r in zip(dialog_list,resultlist):\n",
    "                epl_list.append({\"utterance\":d, \"3persona\":r})\n",
    "            #newdic = {\"current\" : dialog_list, \"persona_list\": persona_list, \"extracted_persona_list\":epl_list}\n",
    "            newdic = {\"persona_list\": persona_list, \"extracted_persona_list\":epl_list}\n",
    "            fout.write(json.dumps(newdic, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What is Sarah's favorite animal?\",\n",
      " \"Sarah's favorite food is mexican food.\",\n",
      " \"Sarah's mother is very traditional while Sarah prefers to be more free \"\n",
      " 'spirited.']\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Sarah's favorite animal?\"\n",
    "personalist = ['Sarah is 24 years old.', \n",
    "               'Sarah currently lives in Canada.', \n",
    "               \"Sarah is a swim coach at Sarah's local pool.\", \n",
    "               'Sarah is studying to be a computer programmer.', \n",
    "               'Sarah is also a graduate student.', \n",
    "               'Sarah is now looking for a new job.', \n",
    "               \"Sarah's mother is very traditional while Sarah prefers to be more free spirited.\", \n",
    "               \"Sarah's family and Sarah are from India.\", \n",
    "               \"Sarah's favorite music genre is death metal.\", \n",
    "               'Sarah is a famous twitch streamer.', \n",
    "               'Sarah likes watching war documentaries.', \n",
    "               \"Sarah's favorite food is mexican food.\",\n",
    "               \"What is Sarah's favorite animal?\"\n",
    "              ]\n",
    "pprint(rt.retrieve_top_summaries( # here is using encodings.?!@\n",
    "                question, personalist, None, topk=3\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dprvenv",
   "language": "python",
   "name": "dprvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
