{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leadawon5/gitfiles/venvs/huggvenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "import json\n",
    "from ast import literal_eval # 걍 eval쓰면 스트링을 배열로 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, DPRQuestionEncoder, DPRContextEncoder\n",
    "from typing import List\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "class BiEncoderRetriever:\n",
    "    def __init__(self) -> None:\n",
    "        self.device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-question-encoder\")\n",
    "        self.question_encoder = DPRQuestionEncoder.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-question-encoder\").to(self.device)\n",
    "        self.ctxt_encoder = DPRContextEncoder.from_pretrained(\"sivasankalpp/dpr-multidoc2dial-structure-ctx-encoder\").to(self.device)\n",
    "\n",
    "    def encode_summaries(self, summaries: List[str]):\n",
    "        input_dict = self.tokenizer(summaries, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        del input_dict[\"token_type_ids\"]\n",
    "        return self.ctxt_encoder(**input_dict)['pooler_output']\n",
    "\n",
    "    def encode_question(self, question: str):\n",
    "        input_dict = self.tokenizer(question, padding='max_length', max_length=32, truncation=True, return_tensors=\"pt\").to(self.device)\n",
    "        del input_dict[\"token_type_ids\"]\n",
    "        return self.question_encoder(**input_dict)['pooler_output']\n",
    "\n",
    "    def retrieve_top_summaries(self, question: str, summaries: List[str], encoded_summaries: np.ndarray = None, topk: int = 5):\n",
    "        encoded_question = self.encode_question(question)\n",
    "        if encoded_summaries is None:\n",
    "            encoded_summaries = self.encode_summaries(summaries)\n",
    "        else:\n",
    "            encoded_summaries = torch.from_numpy(encoded_summaries).to(self.device)\n",
    "\n",
    "        scores = torch.mm(encoded_question, encoded_summaries.T)\n",
    "        # print(encoded_question.shape)\n",
    "        # print(encoded_summaries.T.shape)\n",
    "        if topk >= len(summaries):\n",
    "            return summaries\n",
    "        top_k = torch.topk(scores, topk).indices.squeeze()\n",
    "        \n",
    "        #print(\"all scores : \")\n",
    "        #for i,v in enumerate(scores[0]):\n",
    "            #print(int(v.item()),end=\" \")\n",
    "        #print()\n",
    "        \n",
    "        return [summaries[i] for i in top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = BiEncoderRetriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './bigdata/persona_output.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3199061/3829031208.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./bigdata/persona_output.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./bigdata/extracted_persona_session3_v1.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdialogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdialog\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdialogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './bigdata/persona_output.jsonl'"
     ]
    }
   ],
   "source": [
    "with open(\"./output.jsonl\",\"w\") as fout:\n",
    "    print(\"start!\")\n",
    "\n",
    "with open(\"./persona_dialog.jsonl\", \"r\") as dialogs:\n",
    "    for num,dialog in enumerate(dialogs):\n",
    "        if num == 500:\n",
    "            break;\n",
    "        else:\n",
    "            print(f\"now {num} dialog\")\n",
    "        dic = literal_eval(dialog)\n",
    "        dialog_list = dic[\"current\"]\n",
    "        persona_list = dic[\"persona_list\"]\n",
    "        \n",
    "        \n",
    "        with open(\"./output.jsonl\",\"a\") as fout:\n",
    "            resultlist = []\n",
    "            for i,v in enumerate(dialog_list):\n",
    "                \n",
    "                question = \"\".join(v.split()[2:])\n",
    "                personalist = persona_list\n",
    "                resultlist.append(rt.retrieve_top_summaries(question, personalist, None, topk=3))\n",
    "            epl_list = []\n",
    "            for d,r in zip(dialog_list,resultlist):\n",
    "                epl_list.append({\"utterance\":d, \"3persona\":r})\n",
    "            #newdic = {\"current\" : dialog_list, \"persona_list\": persona_list, \"extracted_persona_list\":epl_list}\n",
    "            newdic = {\"persona_list\": persona_list, \"extracted_persona_list\":epl_list}\n",
    "            fout.write(json.dumps(newdic, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What is Sarah's favorite animal?\",\n",
      " \"Sarah's favorite food is mexican food.\",\n",
      " \"Sarah's mother is very traditional while Sarah prefers to be more free \"\n",
      " 'spirited.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "question = \"What is Sarah's favorite animal?\"\n",
    "personalist = ['Sarah is 24 years old.', \n",
    "               'Sarah currently lives in Canada.', \n",
    "               \"Sarah is a swim coach at Sarah's local pool.\", \n",
    "               'Sarah is studying to be a computer programmer.', \n",
    "               'Sarah is also a graduate student.', \n",
    "               'Sarah is now looking for a new job.', \n",
    "               \"Sarah's mother is very traditional while Sarah prefers to be more free spirited.\", \n",
    "               \"Sarah's family and Sarah are from India.\", \n",
    "               \"Sarah's favorite music genre is death metal.\", \n",
    "               'Sarah is a famous twitch streamer.', \n",
    "               'Sarah likes watching war documentaries.', \n",
    "               \"Sarah's favorite food is mexican food.\",\n",
    "               \"What is Sarah's favorite animal?\"\n",
    "              ]\n",
    "pprint(rt.retrieve_top_summaries( # here is using encodings.?!@\n",
    "                question, personalist, None, topk=3\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggvenv",
   "language": "python",
   "name": "huggvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
