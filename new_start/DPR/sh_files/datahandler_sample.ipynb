{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dataset', 'question', 'answers', 'positive_ctxs', 'negative_ctxs', 'hard_negative_ctxs'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 파일 열기\n",
    "with open('./downloads/data/retriever/nq-dev.json', 'r') as infile, open(\"./sample.json\",\"w\") as outfile:\n",
    "    # JSON 내용을 Python 리스트로 로드\n",
    "    data = json.load(infile)\n",
    "\n",
    "# 이제 'data' 변수는 Python 리스트입니다.\n",
    "# 예를 들어, 리스트의 첫 번째 항목에 접근하려면 data[0]을 사용합니다.\n",
    "    print(data[0].keys())\n",
    "    \n",
    "    small_data = data[10:20]\n",
    "    \n",
    "    for i in range(len(small_data)):\n",
    "        small_data[i][\"positive_ctxs\"] = small_data[i][\"positive_ctxs\"][:4]\n",
    "        small_data[i][\"negative_ctxs\"] = small_data[i][\"negative_ctxs\"][:4]\n",
    "        small_data[i][\"hard_negative_ctxs\"] = small_data[i][\"hard_negative_ctxs\"][:4]\n",
    "    \n",
    "    json.dump(small_data,outfile,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "number of questions\n",
      "6515\n",
      "mean number of positive_ctx\n",
      "5.5\n",
      "mean number of neg_ctx\n",
      "50.0\n",
      "mean haed neg_ctx\n",
      "95.5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"start\")\n",
    "with open('./downloads/data/retriever/nq-dev.json', 'r') as infile, open(\"./sample.json\",\"w\") as outfile:\n",
    "    data = json.load(infile)\n",
    "    print(\"number of questions\")\n",
    "    print(len(data))\n",
    "    \n",
    "    sum_pos = 0\n",
    "    sum_neg = 0\n",
    "    sum_hneg = 0\n",
    "    \n",
    "    for i in range(len(small_data)):\n",
    "        sum_pos+=len(data[i][\"positive_ctxs\"])\n",
    "        sum_neg+=len(data[i][\"negative_ctxs\"])\n",
    "        sum_hneg+=len(data[i][\"hard_negative_ctxs\"])\n",
    "    \n",
    "    print(\"mean number of positive_ctx\")\n",
    "    print(sum_pos/len(small_data))\n",
    "    print(\"mean number of neg_ctx\")\n",
    "    print(sum_neg/len(small_data))\n",
    "    print(\"mean haed neg_ctx\")\n",
    "    print(sum_hneg/len(small_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "number of questions\n",
      "58880\n",
      "mean number of positive_ctx\n",
      "11.0\n",
      "mean number of neg_ctx\n",
      "50.0\n",
      "mean haed neg_ctx\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"start\")\n",
    "with open('./downloads/data/retriever/nq-train.json', 'r') as infile, open(\"./sample.json\",\"w\") as outfile:\n",
    "    data = json.load(infile)\n",
    "    print(\"number of questions\")\n",
    "    print(len(data))\n",
    "    \n",
    "    sum_pos = 0\n",
    "    sum_neg = 0\n",
    "    sum_hneg = 0\n",
    "    \n",
    "    for i in range(len(small_data)):\n",
    "        sum_pos+=len(data[i][\"positive_ctxs\"])\n",
    "        sum_neg+=len(data[i][\"negative_ctxs\"])\n",
    "        sum_hneg+=len(data[i][\"hard_negative_ctxs\"])\n",
    "    \n",
    "    print(\"mean number of positive_ctx\")\n",
    "    print(sum_pos/len(small_data))\n",
    "    print(\"mean number of neg_ctx\")\n",
    "    print(sum_neg/len(small_data))\n",
    "    print(\"mean haed neg_ctx\")\n",
    "    print(sum_hneg/len(small_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oneline\n"
     ]
    }
   ],
   "source": [
    "## dawon custom data maker\n",
    "\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "\n",
    "# 파일 열기\n",
    "with open(\"./downloads/persona_utterance_pair_process.txt\",\"r\") as infile, open(\"./downloads/data/retriever/dawon-train.json\",\"w\") as trainoutfile, open(\"./downloads/data/retriever/dawon-dev.json\",\"w\") as validoutfile:\n",
    "    # JSON 내용을 Python 리스트로 로드\n",
    "    org_data = []\n",
    "    for line in infile:\n",
    "        print(\"oneline\")\n",
    "        line_data = ast.literal_eval(line.strip())\n",
    "        org_data = line_data\n",
    "    \n",
    "    persona_pool = []\n",
    "    \n",
    "    for pair in org_data:\n",
    "        persona_pool.append(pair[1])\n",
    "\n",
    "    \n",
    "    train_data = []\n",
    "    valid_data = []\n",
    "    for i,v in enumerate(org_data):\n",
    "        \n",
    "\n",
    "        dic = {\"dataset\":\"dawon_custom_dataset\",\"question\":\" \".join(v[0].split()[2:]),\"answers\":[\"123\"],\"positive_ctxs\":[{\"title\":\"123\",\"text\":\"Speaker \"+\" \".join(v[1].split()[2:])}],\"negative_ctxs\":[],\"hard_negative_ctxs\":[]}\n",
    "        negs = []\n",
    "        while len(negs) < 20:\n",
    "            sel_neg = random.choice(persona_pool)\n",
    "            if sel_neg == v[1]:\n",
    "                sel_neg = random.choice(persona_pool)\n",
    "            negs.append(sel_neg)\n",
    "        for neg in negs[:10]:\n",
    "            dic[\"negative_ctxs\"].append({\"title\":\"123\",\"text\":\"Speaker \"+\" \".join(neg.split()[2:])})\n",
    "        for neg in negs[10:20]:\n",
    "            dic[\"hard_negative_ctxs\"].append({\"title\":\"123\",\"text\":\"Speaker \"+\" \".join(neg.split()[2:])})\n",
    "        if len(org_data) * 0.2 < i:\n",
    "            train_data.append(dic)\n",
    "        else:\n",
    "            valid_data.append(dic)\n",
    "        \n",
    "    \n",
    "    json.dump(train_data,trainoutfile,ensure_ascii=False)\n",
    "    json.dump(valid_data,validoutfile,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                 id                                               text  \\\n",
      "0                1  Aaron Aaron ( or ; \"Ahärôn\") is a prophet, hig...   \n",
      "1                2  God at Sinai granted Aaron the priesthood for ...   \n",
      "2                3  his rod turn into a snake. Then he stretched o...   \n",
      "3                4  however, Aaron and Hur remained below to look ...   \n",
      "4                5  Aaron and his sons to the priesthood, and arra...   \n",
      "...            ...                                                ...   \n",
      "21015319  21015320  Rouvikonas Rouvikonas (Rubicon, in Greek \"Ρουβ...   \n",
      "21015320  21015321  deemed insignificant by the police, authoritie...   \n",
      "21015321  21015322  Limelight centre Limelight is a community heal...   \n",
      "21015322  21015323  best older people's housing development and Be...   \n",
      "21015323  21015324  committee was established before the building ...   \n",
      "\n",
      "                     title  \n",
      "0                    Aaron  \n",
      "1                    Aaron  \n",
      "2                    Aaron  \n",
      "3                    Aaron  \n",
      "4                    Aaron  \n",
      "...                    ...  \n",
      "21015319        Rouvikonas  \n",
      "21015320        Rouvikonas  \n",
      "21015321  Limelight centre  \n",
      "21015322  Limelight centre  \n",
      "21015323  Limelight centre  \n",
      "\n",
      "[21015324 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"./downloads/data/wikipedia_split/psgs_w100.tsv\",delimiter='\\t')\n",
    "print(dataset.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21015324 entries, 0 to 21015323\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Dtype \n",
      "---  ------  ----- \n",
      " 0   id      int64 \n",
      " 1   text    object\n",
      " 2   title   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 481.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# DataFrame 정보 출력\n",
    "dataset.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'text', 'title'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 컬럼 이름 출력\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                       1\n",
       "text     Aaron Aaron ( or ; \"Ahärôn\") is a prophet, hig...\n",
       "title                                                Aaron\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 원본 데이터셋 로드\n",
    "dataset = pd.read_csv(\"./downloads/data/wikipedia_split/psgs_w100.tsv\", delimiter='\\t')\n",
    "\n",
    "# 데이터셋에서 100개의 샘플 선택\n",
    "sample_dataset = dataset.sample(100)\n",
    "\n",
    "# 샘플 데이터셋을 'sample.tsv'로 저장\n",
    "sample_dataset.to_csv(\"./sample.tsv\", sep='\\t', index=False)\n",
    "\n",
    "\n",
    "# 필요한 행의 수\n",
    "required_rows = 50\n",
    "\n",
    "# 기존 데이터셋에서 필요한 개수만큼 행 선택\n",
    "reduced_dataset = sample_dataset.head(required_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggvenv",
   "language": "python",
   "name": "huggvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
